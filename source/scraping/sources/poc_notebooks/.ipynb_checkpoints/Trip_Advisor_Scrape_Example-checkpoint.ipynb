{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook will walk through a basic example of scraping a web page. I'll include a few functions that won't really change too much from site to site (like getting a page via requests or selenium or an api call or whatever), in order to make everything contained in here. The main idea is that we just want functions that will take pages from various sites and conver them to data.\n",
    "\n",
    "If you've never used a notebook before, just shift-enter on each cell. The functions and variables will be created and stored in the session you are running so that the next time you run a cell you can use whatever you just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities- you shouldn't need to worry about these, just run once\n",
    "\"\"\" Extracts content from a given url\n",
    "\"\"\"  \n",
    "def get_link_content(url, endpoint = \"\", params = None, proxies = None):\n",
    "    result = requests.get(url + endpoint, params, proxies = proxies)\n",
    "    soup = BeautifulSoup(result.content, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "\"\"\" Extracts text from a specific item.\n",
    "\"\"\"  \n",
    "def get_text(content):\n",
    "    try:\n",
    "        return clean_text(content.text)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    text_ascii = re.sub(r'[^\\x00-\\x7F]','', text)\n",
    "    return text_ascii.strip(\"[\\n| ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start with just being able to parse a restaurant page for trip advisor.\n",
    "# We will need to do multipl things from a given site\n",
    "# Eventually, we will need to do a similar task for parsing map search pages, user pages, etc.\n",
    "# But for now let's start with the restaurant page from lafayette\n",
    "TEST_URL = \"https://www.tripadvisor.com/Restaurant_Review-g28970-d1318070-Reviews-Lafayette_Restaurant-Washington_DC_District_of_Columbia.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will get us a nice parsable object to work with (try printing out the whole mess if you like)\n",
    "soup = get_link_content(TEST_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you visit the actual page, you can browse around and find objects that you may want to turn into data features. Right click and inspect element to see the part of the html in which this object resides. For example if I click on the rating, I see something like:\n",
    "\n",
    "<span class=\"restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl\">\n",
    "    \"4.5\"\n",
    "<\\span>\n",
    "\n",
    "There are a few ways I can search for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl\">4.5<!-- --> </span>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search by class name\n",
    "soup.find('span', attrs= {'class' : 'restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl\">4.5<!-- --> </span>, <span class=\"row_num is-shown-at-tablet\">3</span>, <span class=\"row_num is-shown-at-tablet\">4</span>, <span class=\"row_num \">3</span>, <span class=\"row_num \">4</span>, <span class=\"numHelp emphasizeWithColor\">1  </span>, <span class=\"numHelp emphasizeWithColor\">1  </span>, <span class=\"badgetext\">2</span>, <span class=\"badgetext\">2</span>, <span class=\"badgetext\">2</span>, <span class=\"numHelp emphasizeWithColor\">2  </span>, <span class=\"badgetext\">2</span>, <span class=\"numHelp emphasizeWithColor\">2  </span>, <span class=\"numHelp emphasizeWithColor\">1  </span>, <span class=\"numHelp emphasizeWithColor\">1  </span>]\n"
     ]
    }
   ],
   "source": [
    "# Just loop through all the 'span' objects and find ones that look something like a review\n",
    "spans = soup.findAll('span')\n",
    "ratings = []\n",
    "for span in spans:\n",
    "    try:\n",
    "        # Capture anything with a number 0-5\n",
    "        text = get_text(span)\n",
    "        num = float(text)\n",
    "        if num >=0 and num < 5:\n",
    "            ratings.append(span)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# In this case, this will get us more than just the ratings we are looking for. So we have to be careful\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, what we need is just a single function that will take in a soup object (assuming its from a page similar to the test page) and will output a dictionary of data containing all the elements we want from that page. This will be plugged into some process which will be designed to loop through lots of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_class(soup, class_name):\n",
    "    return get_text(soup.find('span', attrs = {'class' : class_name}))\n",
    "\n",
    "# Takes a restaurant page and converts to a dictionary of items we care about\n",
    "def soup_to_dict_restaurant(restaurant_page_soup):\n",
    "    \n",
    "    # Overall Restaurant Rating\n",
    "    overall_rating = float(search_class(restaurant_page_soup,'restaurants-detail-overview-cards-RatingsOverviewCard__overallRating--nohTl'))\n",
    "    \n",
    "    # Address of the restaurant\n",
    "    street_address = search_class(restaurant_page_soup,'street-address')\n",
    "    \n",
    "    # Number of reviews\n",
    "    review_count_text = search_class(restaurant_page_soup,'reviewCount')\n",
    "    review_count = float(re.sub(' reviews', '', review_count_text))\n",
    "    \n",
    "    ###\n",
    "    \"\"\"\n",
    "    Add in any more items you want to save. From this page, probably:\n",
    "    - Restaurant Tags\n",
    "    - \n",
    "    \"\"\"\n",
    "    ###\n",
    "    \n",
    "    # Build into dictionary\n",
    "    dict_ = {\n",
    "        'address' : street_address,\n",
    "        'rating' : overall_rating,\n",
    "        'num_reviews' : review_count\n",
    "           }\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': '800 16th St NW', 'rating': 4.5, 'num_reviews': 306.0}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it out with our test page\n",
    "soup_to_dict_restaurant(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this process with a user page (https://www.tripadvisor.com/Profile/jujubean79) or a search page (https://www.tripadvisor.com/Restaurants-g28970-Washington_DC_District_of_Columbia.html we will need to get the links to the restaurant pages), or other page types on trip advisor. It would be really helpful to have good documentation for each site on:\n",
    "* What types of pages that site has (user, restaurant, individual review, search page, etc.)\n",
    "* How we will need to loop through those pages (do we start with a search of restaurants, then loop through links to restaurants, then links to users?)\n",
    "* List of information grabbed from each page type\n",
    "\n",
    "Gathering this info for each site will take time, but ideally, we should be able to take in a function for each page type- converting that page to a dictionary- and plug it in to a more generalizable process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
